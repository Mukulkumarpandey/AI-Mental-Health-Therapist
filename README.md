ğŸ§  AI Mental Health Therapist

An AI-powered Mental Health Support System built using:

âš¡ FastAPI (Backend API)

ğŸ¨ Streamlit (Frontend UI)

ğŸ¤– LangChain + LangGraph (AI Agent Framework)

ğŸ§  Ollama (MedGemma Model)

ğŸ“ Twilio (Emergency Calling)

ğŸ”¥ OpenAI (LLM Orchestration)

ğŸš€ Features

    âœ… Empathetic AI mental health conversations
    âœ… ReAct-based AI agent with tool usage
    âœ… Emergency call support via Twilio
    âœ… Therapist location recommendation tool
    âœ… Streamlit Chat UI
    âœ… FastAPI production-ready backend

ğŸ—ï¸ Project Architecture
User (Streamlit UI)
        â†“
FastAPI Backend (/ask endpoint)
        â†“
LangGraph ReAct Agent
        â†“
Tools:
   â€¢ MedGemma (Therapeutic Response)
   â€¢ Emergency Call (Twilio)
   â€¢ Therapist Locator

ğŸ“‚ Project Structure
â”œâ”€â”€ frontend.py        # Streamlit UI
â”œâ”€â”€ main.py            # FastAPI backend
â”œâ”€â”€ ai_agent.py        # LangGraph ReAct Agent
â”œâ”€â”€ tools.py           # MedGemma + Twilio tools
â”œâ”€â”€ config.py          # API Keys and credentials
â””â”€â”€ README.md

âš™ï¸ Installation Guide
1ï¸âƒ£ Clone the Repository
git clone https://github.com/yourusername/ai-mental-health-therapist.git
cd ai-mental-health-therapist

2ï¸âƒ£ Create Virtual Environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install fastapi uvicorn streamlit langchain langgraph langchain-openai ollama twilio requests

4ï¸âƒ£ Setup Environment Variables

Edit config.py:

TWILIO_ACCOUNT_SID = "your_sid"
TWILIO_AUTH_TOKEN = "your_token"
TWILIO_FROM_NUMBER = "your_twilio_number"
EMERGENCY_CONTACT = "emergency_number"
OPENAI_API_KEY = "your_openai_key"


âš ï¸ IMPORTANT: Never push real API keys to GitHub. Use .env file in production.

5ï¸âƒ£ Install & Run Ollama + MedGemma

Install Ollama from:

ğŸ‘‰ https://ollama.com

Pull MedGemma model:

ollama pull alibayram/medgemma:4b


Run Ollama server:

ollama serve

â–¶ï¸ Running the Application
Start FastAPI Backend
uvicorn main:app --reload


Backend runs at:

http://localhost:8000

Start Streamlit Frontend
streamlit run frontend.py


Frontend runs at:

http://localhost:8501
